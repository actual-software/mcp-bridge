package gateway

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"go.uber.org/zap/zaptest"

	common "github.com/poiley/mcp-bridge/pkg/common/config"
	"github.com/poiley/mcp-bridge/services/router/internal/config"
	"github.com/poiley/mcp-bridge/services/router/pkg/mcp"
)

// TestGatewayClient_HealthMonitoring tests comprehensive health monitoring features
func TestGatewayClient_HealthMonitoring(t *testing.T) {
	logger := zaptest.NewLogger(t)

	tests := []struct {
		name                    string
		healthCheckInterval     time.Duration
		expectedHealthChecks    int
		simulateUnhealthyPeriod bool
		expectedRecovery        bool
	}{
		{
			name:                 "frequent_health_checks",
			healthCheckInterval:  50 * time.Millisecond,
			expectedHealthChecks: 4, // Over 200ms test period
			simulateUnhealthyPeriod: false,
			expectedRecovery:     true,
		},
		{
			name:                 "health_degradation_and_recovery",
			healthCheckInterval:  30 * time.Millisecond,
			expectedHealthChecks: 6, // Over 200ms test period
			simulateUnhealthyPeriod: true,
			expectedRecovery:     true,
		},
		{
			name:                 "slow_health_checks",
			healthCheckInterval:  100 * time.Millisecond,
			expectedHealthChecks: 2, // Over 200ms test period
			simulateUnhealthyPeriod: false,
			expectedRecovery:     true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			var healthCheckCount int64
			var unhealthyPeriod int64

			client := &HealthMonitoringMockClient{
				healthCheckInterval: tt.healthCheckInterval,
				simulateUnhealthy:   tt.simulateUnhealthyPeriod,
				onHealthCheck: func(healthy bool) {
					atomic.AddInt64(&healthCheckCount, 1)
					if !healthy {
						atomic.AddInt64(&unhealthyPeriod, 1)
					}
				},
			}

			ctx := context.Background()
			if err := client.Connect(ctx); err != nil {
				t.Fatalf("Failed to connect client: %v", err)
			}
			defer client.Close()

			// Start health monitoring
			client.StartHealthMonitoring()

			// Run test for a specific duration
			time.Sleep(200 * time.Millisecond)

			client.StopHealthMonitoring()

			// Verify health check behavior
			actualChecks := atomic.LoadInt64(&healthCheckCount)
			if actualChecks < int64(tt.expectedHealthChecks-1) || actualChecks > int64(tt.expectedHealthChecks+2) {
				t.Errorf("Expected approximately %d health checks, got %d", tt.expectedHealthChecks, actualChecks)
			}

			if tt.simulateUnhealthyPeriod {
				if unhealthyPeriod == 0 {
					t.Error("Expected some unhealthy periods but got none")
				}
				if tt.expectedRecovery && client.GetLastHealthStatus() != "healthy" {
					t.Error("Expected recovery to healthy state")
				}
			}

			t.Logf("Health monitoring test %s: checks=%d, unhealthy_periods=%d, final_status=%s", 
				tt.name, actualChecks, unhealthyPeriod, client.GetLastHealthStatus())
		})
	}
}

// TestGatewayPool_HealthBasedRouting tests health-based endpoint selection
func TestGatewayPool_HealthBasedRouting(t *testing.T) {
	logger := zaptest.NewLogger(t)

	// Create endpoints with different health statuses
	endpoints := []config.GatewayEndpoint{
		{
			URL:      "ws://healthy-gateway:8080",
			Weight:   10,
			Priority: 1,
			Tags:     []string{"primary"},
		},
		{
			URL:      "ws://unhealthy-gateway:8080",
			Weight:   10,
			Priority: 1,
			Tags:     []string{"primary"},
		},
		{
			URL:      "ws://backup-gateway:8080",
			Weight:   5,
			Priority: 2,
			Tags:     []string{"backup"},
		},
	}

	poolConfig := config.GatewayPoolConfig{
		Endpoints: endpoints,
		LoadBalancer: config.LoadBalancerConfig{
			Strategy:        "round_robin",
			HealthCheckPath: "/health",
		},
	}

	// Create gateway pool
	pool, err := NewGatewayPool(poolConfig, logger)
	if err != nil {
		t.Fatalf("Failed to create gateway pool: %v", err)
	}
	defer pool.Close()

	// Simulate health status changes
	healthyEndpoint := &pool.endpoints[0]
	unhealthyEndpoint := &pool.endpoints[1]
	backupEndpoint := &pool.endpoints[2]

	// Mark second endpoint as unhealthy
	unhealthyEndpoint.UpdateHealth(false, "Connection failed")

	// Test endpoint selection with health considerations
	selectionCounts := make(map[string]int)
	const numSelections = 100

	for i := 0; i < numSelections; i++ {
		endpoint := pool.SelectEndpoint()
		if endpoint != nil {
			selectionCounts[endpoint.URL]++
		}
	}

	t.Logf("Endpoint selection results:")
	for url, count := range selectionCounts {
		t.Logf("  %s: %d selections", url, count)
	}

	// Verify healthy endpoints are preferred
	healthySelections := selectionCounts[healthyEndpoint.URL]
	unhealthySelections := selectionCounts[unhealthyEndpoint.URL]
	backupSelections := selectionCounts[backupEndpoint.URL]

	if unhealthySelections > 0 {
		t.Errorf("Unhealthy endpoint was selected %d times, expected 0", unhealthySelections)
	}

	if healthySelections == 0 {
		t.Error("Healthy primary endpoint was never selected")
	}

	// Test recovery scenario
	unhealthyEndpoint.UpdateHealth(true, "Recovered")

	// After recovery, both primary endpoints should be selected
	recoverySelections := make(map[string]int)
	for i := 0; i < 50; i++ {
		endpoint := pool.SelectEndpoint()
		if endpoint != nil {
			recoverySelections[endpoint.URL]++
		}
	}

	recoveredSelections := recoverySelections[unhealthyEndpoint.URL]
	if recoveredSelections == 0 {
		t.Error("Recovered endpoint was not selected after health recovery")
	}

	t.Logf("After recovery:")
	for url, count := range recoverySelections {
		t.Logf("  %s: %d selections", url, count)
	}
}

// TestGatewayClient_CircuitBreakerIntegration tests circuit breaker behavior with health monitoring
func TestGatewayClient_CircuitBreakerIntegration(t *testing.T) {
	logger := zaptest.NewLogger(t)

	var consecutiveFailures int64
	var circuitBreakerTrips int64
	var circuitBreakerResets int64

	client := &CircuitBreakerMockClient{
		failureThreshold: 3,
		recoveryTimeout:  100 * time.Millisecond,
		onFailure: func() {
			atomic.AddInt64(&consecutiveFailures, 1)
		},
		onCircuitOpen: func() {
			atomic.AddInt64(&circuitBreakerTrips, 1)
		},
		onCircuitClose: func() {
			atomic.AddInt64(&circuitBreakerResets, 1)
			atomic.StoreInt64(&consecutiveFailures, 0)
		},
	}

	ctx := context.Background()
	if err := client.Connect(ctx); err != nil {
		t.Fatalf("Failed to connect client: %v", err)
	}
	defer client.Close()

	// Send requests that will trigger circuit breaker
	const numRequests = 10
	var successCount int64
	var failureCount int64

	for i := 0; i < numRequests; i++ {
		req := &mcp.Request{
			JSONRPC: "2.0",
			Method:  "circuit_breaker_test",
			ID:      fmt.Sprintf("cb-test-%d", i),
		}

		err := client.SendRequest(req)
		if err != nil {
			atomic.AddInt64(&failureCount, 1)
		} else {
			atomic.AddInt64(&successCount, 1)
		}

		// Small delay between requests
		time.Sleep(10 * time.Millisecond)
	}

	// Wait for potential circuit breaker recovery
	time.Sleep(150 * time.Millisecond)

	// Try more requests after potential recovery
	for i := 0; i < 5; i++ {
		req := &mcp.Request{
			JSONRPC: "2.0",
			Method:  "circuit_breaker_recovery",
			ID:      fmt.Sprintf("cb-recovery-%d", i),
		}

		err := client.SendRequest(req)
		if err != nil {
			atomic.AddInt64(&failureCount, 1)
		} else {
			atomic.AddInt64(&successCount, 1)
		}

		time.Sleep(10 * time.Millisecond)
	}

	t.Logf("Circuit breaker test results:")
	t.Logf("  Successful requests: %d", successCount)
	t.Logf("  Failed requests: %d", failureCount)
	t.Logf("  Consecutive failures: %d", consecutiveFailures)
	t.Logf("  Circuit breaker trips: %d", circuitBreakerTrips)
	t.Logf("  Circuit breaker resets: %d", circuitBreakerResets)

	// Verify circuit breaker behavior
	if circuitBreakerTrips == 0 {
		t.Error("Expected circuit breaker to trip due to consecutive failures")
	}

	if successCount == 0 {
		t.Error("Expected some successful requests")
	}

	// Should see recovery attempts
	if circuitBreakerResets == 0 {
		t.Error("Expected circuit breaker to attempt reset after recovery timeout")
	}
}

// TestGatewayClient_HealthMetricsCollection tests health metric collection and reporting
func TestGatewayClient_HealthMetricsCollection(t *testing.T) {
	logger := zaptest.NewLogger(t)

	metrics := &HealthMetrics{
		ResponseTimes:     make([]time.Duration, 0, 100),
		SuccessCount:      0,
		FailureCount:      0,
		HealthCheckCount:  0,
		LastHealthCheck:   time.Time{},
	}

	client := &MetricsCollectingMockClient{
		metrics: metrics,
		baseLatency: 5 * time.Millisecond,
	}

	ctx := context.Background()
	if err := client.Connect(ctx); err != nil {
		t.Fatalf("Failed to connect client: %v", err)
	}
	defer client.Close()

	// Generate load to collect metrics
	const numRequests = 50
	start := time.Now()

	for i := 0; i < numRequests; i++ {
		req := &mcp.Request{
			JSONRPC: "2.0",
			Method:  "metrics_test",
			ID:      fmt.Sprintf("metrics-%d", i),
		}

		err := client.SendRequest(req)
		if err != nil {
			t.Errorf("Request %d failed: %v", i, err)
		}

		// Simulate health check every 10 requests
		if i%10 == 0 {
			client.PerformHealthCheck()
		}
	}

	totalDuration := time.Since(start)

	// Analyze collected metrics
	metrics.mu.Lock()
	totalResponseTime := time.Duration(0)
	for _, rt := range metrics.ResponseTimes {
		totalResponseTime += rt
	}
	avgResponseTime := totalResponseTime / time.Duration(len(metrics.ResponseTimes))

	successRate := float64(metrics.SuccessCount) / float64(metrics.SuccessCount + metrics.FailureCount) * 100
	throughput := float64(numRequests) / totalDuration.Seconds()
	metrics.mu.Unlock()

	t.Logf("Health metrics collection results:")
	t.Logf("  Total requests: %d", numRequests)
	t.Logf("  Successful requests: %d", metrics.SuccessCount)
	t.Logf("  Failed requests: %d", metrics.FailureCount)
	t.Logf("  Success rate: %.2f%%", successRate)
	t.Logf("  Average response time: %v", avgResponseTime)
	t.Logf("  Throughput: %.2f req/s", throughput)
	t.Logf("  Health checks performed: %d", metrics.HealthCheckCount)
	t.Logf("  Response time samples: %d", len(metrics.ResponseTimes))

	// Verify metrics collection
	if metrics.SuccessCount == 0 {
		t.Error("Expected some successful requests")
	}

	if len(metrics.ResponseTimes) == 0 {
		t.Error("Expected response time measurements")
	}

	if metrics.HealthCheckCount == 0 {
		t.Error("Expected health checks to be performed")
	}

	if successRate < 95.0 {
		t.Errorf("Success rate %.2f%% too low", successRate)
	}

	if avgResponseTime > 50*time.Millisecond {
		t.Errorf("Average response time %v too high", avgResponseTime)
	}
}

// Mock implementations for health monitoring tests

type HealthMonitoringMockClient struct {
	healthCheckInterval time.Duration
	simulateUnhealthy   bool
	onHealthCheck       func(bool)
	healthTicker        *time.Ticker
	stopChan            chan struct{}
	lastHealthStatus    string
	mu                  sync.Mutex
}

func (h *HealthMonitoringMockClient) Connect(ctx context.Context) error {
	h.lastHealthStatus = "healthy"
	return nil
}

func (h *HealthMonitoringMockClient) StartHealthMonitoring() {
	h.stopChan = make(chan struct{})
	h.healthTicker = time.NewTicker(h.healthCheckInterval)

	go func() {
		checkCount := 0
		for {
			select {
			case <-h.healthTicker.C:
				checkCount++
				healthy := true

				// Simulate unhealthy period
				if h.simulateUnhealthy && checkCount >= 2 && checkCount <= 4 {
					healthy = false
				}

				h.mu.Lock()
				if healthy {
					h.lastHealthStatus = "healthy"
				} else {
					h.lastHealthStatus = "unhealthy"
				}
				h.mu.Unlock()

				if h.onHealthCheck != nil {
					h.onHealthCheck(healthy)
				}

			case <-h.stopChan:
				h.healthTicker.Stop()
				return
			}
		}
	}()
}

func (h *HealthMonitoringMockClient) StopHealthMonitoring() {
	if h.stopChan != nil {
		close(h.stopChan)
	}
}

func (h *HealthMonitoringMockClient) GetLastHealthStatus() string {
	h.mu.Lock()
	defer h.mu.Unlock()
	return h.lastHealthStatus
}

func (h *HealthMonitoringMockClient) SendRequest(req *mcp.Request) error { return nil }
func (h *HealthMonitoringMockClient) ReceiveResponse() (*mcp.Response, error) {
	return &mcp.Response{JSONRPC: "2.0", ID: "health-test"}, nil
}
func (h *HealthMonitoringMockClient) SendPing() error      { return nil }
func (h *HealthMonitoringMockClient) IsConnected() bool    { return true }
func (h *HealthMonitoringMockClient) Close() error         { return nil }

type CircuitBreakerMockClient struct {
	failureThreshold    int64
	recoveryTimeout     time.Duration
	onFailure          func()
	onCircuitOpen      func()
	onCircuitClose     func()
	currentFailures    int64
	circuitOpen        bool
	lastFailureTime    time.Time
	mu                 sync.Mutex
}

func (c *CircuitBreakerMockClient) Connect(ctx context.Context) error {
	return nil
}

func (c *CircuitBreakerMockClient) SendRequest(req *mcp.Request) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	// Check if circuit is open and recovery timeout has passed
	if c.circuitOpen && time.Since(c.lastFailureTime) > c.recoveryTimeout {
		c.circuitOpen = false
		c.currentFailures = 0
		if c.onCircuitClose != nil {
			c.onCircuitClose()
		}
	}

	// If circuit is open, fail fast
	if c.circuitOpen {
		return fmt.Errorf("circuit breaker open")
	}

	// Simulate failures for first few requests
	if c.currentFailures < c.failureThreshold {
		c.currentFailures++
		c.lastFailureTime = time.Now()
		if c.onFailure != nil {
			c.onFailure()
		}

		// Trip circuit breaker if threshold reached
		if c.currentFailures >= c.failureThreshold {
			c.circuitOpen = true
			if c.onCircuitOpen != nil {
				c.onCircuitOpen()
			}
		}

		return fmt.Errorf("simulated failure %d", c.currentFailures)
	}

	// After recovery, requests succeed
	return nil
}

func (c *CircuitBreakerMockClient) ReceiveResponse() (*mcp.Response, error) {
	return &mcp.Response{JSONRPC: "2.0", ID: "cb-test"}, nil
}
func (c *CircuitBreakerMockClient) SendPing() error      { return nil }
func (c *CircuitBreakerMockClient) IsConnected() bool    { return true }
func (c *CircuitBreakerMockClient) Close() error         { return nil }

type HealthMetrics struct {
	ResponseTimes    []time.Duration
	SuccessCount     int64
	FailureCount     int64
	HealthCheckCount int64
	LastHealthCheck  time.Time
	mu               sync.Mutex
}

type MetricsCollectingMockClient struct {
	metrics     *HealthMetrics
	baseLatency time.Duration
}

func (m *MetricsCollectingMockClient) Connect(ctx context.Context) error {
	return nil
}

func (m *MetricsCollectingMockClient) SendRequest(req *mcp.Request) error {
	start := time.Now()
	
	// Simulate processing time
	time.Sleep(m.baseLatency)
	
	duration := time.Since(start)

	m.metrics.mu.Lock()
	m.metrics.ResponseTimes = append(m.metrics.ResponseTimes, duration)
	m.metrics.SuccessCount++
	m.metrics.mu.Unlock()

	return nil
}

func (m *MetricsCollectingMockClient) PerformHealthCheck() {
	m.metrics.mu.Lock()
	m.metrics.HealthCheckCount++
	m.metrics.LastHealthCheck = time.Now()
	m.metrics.mu.Unlock()
}

func (m *MetricsCollectingMockClient) ReceiveResponse() (*mcp.Response, error) {
	return &mcp.Response{JSONRPC: "2.0", ID: "metrics-test"}, nil
}
func (m *MetricsCollectingMockClient) SendPing() error      { return nil }
func (m *MetricsCollectingMockClient) IsConnected() bool    { return true }
func (m *MetricsCollectingMockClient) Close() error         { return nil }